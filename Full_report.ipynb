{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sstats\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import time\n",
    "\n",
    "customers = pd.read_csv('customers.csv')\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "customers.drop(columns=[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\",\n",
    "                       \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\"], \n",
    "               inplace=True)\n",
    "\n",
    "data = customers.copy()\n",
    "data[\"Target\"] = (customers[\"Attrition_Flag\"] == \"Attrited Customer\").astype(np.int8)\n",
    "data.drop(columns=\"Attrition_Flag\", inplace=True)\n",
    "data[\"Flag_Male\"] = (customers[\"Gender\"] == \"M\").astype(np.int8)\n",
    "data.drop(columns=\"Gender\", inplace=True)\n",
    "data[\"Card_Category\"] = data[\"Card_Category\"].replace([\"Blue\", \n",
    "                                                       \"Silver\",\n",
    "                                                       \"Gold\",\n",
    "                                                       \"Platinum\"],\n",
    "                                                      [0,1,2,3])\n",
    "# data_dummies[\"Income_Category\"] = data_dummies[\"Income_Category\"].replace([\"Less than $40K\", \n",
    "#                                                            \"$40K - $60K\",\n",
    "#                                                            \"$60K - $80K\",\n",
    "#                                                            \"$80K - $120K\",\n",
    "#                                                            \"$120K +\",\n",
    "#                                                            \"Unknown\"],\n",
    "#                                                           [20,50,70,100,140,None])\n",
    "\n",
    "data_dummies = data.copy()\n",
    "\n",
    "data_dummies = pd.get_dummies(data_dummies, prefix=\"Flag_Inc\", columns=[\"Income_Category\"])\n",
    "data_dummies = pd.get_dummies(data_dummies, prefix=\"Flag_Edu\", columns=[\"Education_Level\"])\n",
    "data_dummies = pd.get_dummies(data_dummies, prefix=\"Flag_Mar\", columns=[\"Marital_Status\"])\n",
    "data_dummies\n",
    "\n",
    "\n",
    "\n",
    "data_dummies_without_first = data.copy()\n",
    "data_dummies_without_first = pd.get_dummies(data_dummies_without_first, drop_first=True, \n",
    "                                                  prefix=\"Flag_Inc\", columns=[\"Income_Category\"])\n",
    "data_dummies_without_first = pd.get_dummies(data_dummies_without_first, drop_first=True, \n",
    "                                                  prefix=\"Flag_Edu\", columns=[\"Education_Level\"])\n",
    "data_dummies_without_first = pd.get_dummies(data_dummies_without_first, drop_first=True, \n",
    "                                                  prefix=\"Flag_Mar\", columns=[\"Marital_Status\"])\n",
    "data_dummies_without_first\n",
    "\n",
    "\n",
    "\n",
    "def KNNFillerMissingData(data, cols=[\"Education_Level\", \"Marital_Status\", \"Income_Category\"], \n",
    "                         missing_indicator=\"Unknown\"):\n",
    "    fitted_KNeighborsClassifiers = []\n",
    "    data_knn = data.copy()\n",
    "    for column_name in cols:\n",
    "        X_train = data[data[column_name] != missing_indicator]\n",
    "        X_train = X_train.drop(columns=cols)\n",
    "        X_train = X_train.drop(columns=[\"CLIENTNUM\"])\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "        y_train = data[data[column_name] != missing_indicator][column_name]\n",
    "\n",
    "        X_test = data[data[column_name] == missing_indicator]\n",
    "        X_test = X_test.drop(columns=cols)\n",
    "        X_test = X_test.drop(columns=[\"CLIENTNUM\"])\n",
    "        scaler = StandardScaler()\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=5)\n",
    "        model.fit(X_train, y_train)\n",
    "        fitted_KNeighborsClassifiers.append(model)\n",
    "        y_preds = model.predict(X_test)\n",
    "\n",
    "        data_knn.loc[data_knn[column_name] == missing_indicator, column_name] = y_preds\n",
    "    data_knn.drop_duplicates(inplace=True)\n",
    "    return data_knn, fitted_KNeighborsClassifiers\n",
    "\n",
    "\n",
    "data_imputed = KNNFillerMissingData(data)[0]\n",
    "data_imputed[\"Income_Category\"] = data_imputed[\"Income_Category\"].replace([\"Less than $40K\", \n",
    "                                                           \"$40K - $60K\",\n",
    "                                                           \"$60K - $80K\",\n",
    "                                                           \"$80K - $120K\",\n",
    "                                                           \"$120K +\"],\n",
    "                                                          [20,50,70,100,140])\n",
    "data_imputed\n",
    "\n",
    "\n",
    "data_imputed_dummy = data_imputed.copy()\n",
    "data_imputed_dummy = pd.get_dummies(data_imputed_dummy, prefix=\"Flag\", columns=[\"Education_Level\"])\n",
    "data_imputed_dummy = pd.get_dummies(data_imputed_dummy, prefix=\"Flag\", columns=[\"Marital_Status\"])\n",
    "data_imputed_dummy\n",
    "\n",
    "\n",
    "data_imputed_dummy_without_first = data_imputed.copy()\n",
    "data_imputed_dummy_without_first = pd.get_dummies(data_imputed_dummy_without_first, drop_first=True, \n",
    "                                                  prefix=\"Flag\", columns=[\"Education_Level\"])\n",
    "data_imputed_dummy_without_first = pd.get_dummies(data_imputed_dummy_without_first, drop_first=True, \n",
    "                                                  prefix=\"Flag\", columns=[\"Marital_Status\"])\n",
    "data_imputed_dummy_without_first\n",
    "\n",
    "def cross_validation(model, sampling, data, k=5, return_importances=False):\n",
    "    score = 0.\n",
    "    balanced_acc = 0.\n",
    "    rec_scor = np.array([0., 0.])\n",
    "    if return_importances:\n",
    "        importances = {}\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    if \"CLIENTNUM\" in data.columns:\n",
    "        data = data.drop(columns=[\"CLIENTNUM\"])\n",
    "    X = data.drop(columns=[\"Target\"])\n",
    "    y = data[\"Target\"]\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        X_resampled, y_resampled, X_test, y_test = sampling(X_train, y_train, X_test, y_test)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score += model.score(X_test, y_test)\n",
    "        balanced_acc += balanced_accuracy_score(y_test, y_pred)\n",
    "        rec_scor += recall_score(y_test, y_pred, average=None)\n",
    "        if return_importances:\n",
    "            for key, val in zip(X_resampled.columns, data_tree.feature_importances_):\n",
    "                if key in importances:\n",
    "                    importances[key] += val\n",
    "                else:\n",
    "                    importances[key] = val\n",
    "    if return_importances:\n",
    "        for key, val in importances.items():\n",
    "            importances[key] /= k\n",
    "        importances = sorted(list(importances.items()), key=lambda x: -x[1])\n",
    "        return score/k, balanced_acc/k, rec_scor/k, importances\n",
    "    return score/k, balanced_acc/k, rec_scor/k\n",
    "\n",
    "\n",
    "\n",
    "def over_sampling(X_train, y_train, X_test, y_test):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled, X_test, y_test\n",
    "\n",
    "\n",
    "def under_sampling(X_train, y_train, X_test, y_test):\n",
    "    ros = RandomUnderSampler(random_state=0)\n",
    "    X_train.reset_index(inplace=True, drop=True)\n",
    "    y_train.reset_index(inplace=True, drop=True)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_test = pd.concat([X_test, X_train.loc[list(set(X_train.index).difference(set(ros.sample_indices_)))]], axis=0)\n",
    "    y_test = pd.concat([y_test, y_train.loc[list(set(y_train.index).difference(set(ros.sample_indices_)))]], axis=0)\n",
    "    return X_resampled, y_resampled, X_test, y_test\n",
    "\n",
    "\n",
    "def smote_sampling(categorical_columns, columns_to_dummy):\n",
    "    def f(X_train, y_train, X_test, y_test):\n",
    "        sm = SMOTENC(categorical_features=categorical_columns)\n",
    "        X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "        for col in columns_to_dummy:\n",
    "            X_resampled = pd.get_dummies(X_resampled, prefix=\"Flag_\" + col[:3], columns=[col])\n",
    "            X_test = pd.get_dummies(X_test, prefix=\"Flag_\" + col[:3], columns=[col])\n",
    "        return X_resampled, y_resampled, X_test, y_test\n",
    "    return f\n",
    "\n",
    "\n",
    "def model_score_recall_with_wrapper(data, model, num_features, sampling=over_sampling, direction='forward'):\n",
    "    X = data.drop(columns=[\"CLIENTNUM\", 'Target'])\n",
    "    y = data[\"Target\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "    ros = RandomOverSampler(random_state = 2137)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    sfs = SequentialFeatureSelector(estimator = model, n_features_to_select = num_features, \n",
    "                                direction = direction, n_jobs=3)\n",
    "    sfs.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    columns = list(X.columns[sfs.get_support()])\n",
    "    \n",
    "    temp_data = data[columns + ['Target']]\n",
    "        \n",
    "    score, balance, recalls, importances = cross_validation(model, sampling, temp_data, k=5, \n",
    "                                                        return_importances=True)\n",
    "    return score, recalls\n",
    "\n",
    "\n",
    "\n",
    "def model_score_recall_with_wrapper_iterative(data, model, max_num_features=25, sampling=over_sampling, \n",
    "                                              direction='forward', verbose=True):\n",
    "    scores = []\n",
    "    recall_0 = []\n",
    "    recall_1 = []\n",
    "    if verbose:\n",
    "        t0 = time.time()\n",
    "    \n",
    "    try: \n",
    "        for num_features in range(2, max_num_features + 1):\n",
    "            score, recalls = model_score_recall_with_wrapper(data, model, num_features, sampling, direction)\n",
    "            scores.append(score)\n",
    "            recall_0.append(recalls[0])\n",
    "            recall_1.append(recalls[1])\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"One iteration\", num_features, ' Time:', int(time.time() - t0) // 60)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        return scores, recall_0, recall_1\n",
    "        \n",
    "    return scores, recall_0, recall_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
